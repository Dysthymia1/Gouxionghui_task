# 项目简介
* Task2 - 爬虫模块：使用网络爬虫从指定网站抓取原始文本数据。
* Task3 - 数据预处理与可视化：对采集到的数据进行清洗、分词、去噪处理，并借助可视化手段探索数据特征。
* Task4 - LDA建模：应用 Latent Dirichlet Allocation（LDA）主题模型，对文本数据进行主题挖掘和建模。
* Task6 - 情感分析：基于百度云 API 对文本进行情感分类，评估文本正负面倾向。

## 致谢
本项目在数据采集部分借鉴并使用了以下开源项目的部分代码，特此致谢：
[WeiboSpider](https://github.com/nghuyong/WeiboSpider)：高性能的微博爬虫框架，支持全站内容抓取。
[Bilibili_crawler](https://github.com/linyuye/Bilibili_crawler)：B站弹幕与评论爬取工具，适用于舆情分析与内容挖掘。
感谢上述项目的作者为开源社区做出的贡献。
