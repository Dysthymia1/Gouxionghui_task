{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "weibo_total_comments_path = \"../result/task3/weibo_total_comments.csv\"\n",
    "bilibili_total_comments_path = \"../result/task3/bilibili_total_comments.csv\"\n",
    "weibo_df = pd.read_csv(weibo_total_comments_path)\n",
    "bilibili_df = pd.read_csv(bilibili_total_comments_path)\n",
    "\n",
    "stops_path = \"resources/stopword.txt\"\n",
    "user_dict_path = \"resources/user_dict.txt\"\n",
    "\n",
    "output_path = \"../result/task4\""
   ],
   "id": "4da5e2ff0ba9553c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "289ec3b82b4db345"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "def load_stops():\n",
    "    stops = []\n",
    "    with open(stops_path, encoding='utf-8') as fr:\n",
    "        for line in fr:\n",
    "            stops.append(line.strip().lower())\n",
    "    return stops\n",
    "\n",
    "def process_text(text, stopwords):\n",
    "    words = jieba.cut(text)  # 使用 jieba 分词\n",
    "    # 过滤停用词并去除空白词\n",
    "    filtered_words = [word.strip() for word in words if word.strip() not in stopwords and len(word.strip()) > 1]\n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "# 1. 加载停用词\n",
    "STOPS = load_stops()\n",
    "# 2. 加载自定义词典\n",
    "jieba.load_userdict(user_dict_path)\n"
   ],
   "id": "ab82b859aea7cbdc"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def tokenize_comments(df, stopwords):\n",
    "    \"\"\"\n",
    "    将 DataFrame 中的评论内容进行分词处理，并返回列表的列表形式。\n",
    "    \n",
    "    参数:\n",
    "        df (pd.DataFrame): 包含文本数据的 DataFrame\n",
    "        stopwords (set): 停用词集合\n",
    "        text_column (str): 需要处理的列名，默认是 'content'\n",
    "\n",
    "    返回:\n",
    "        List[List[str]]: 分词后的评论列表\n",
    "    \"\"\"\n",
    "    tokenized_docs = []\n",
    "    for text in df['content'].fillna(''):  # 确保空值处理\n",
    "        tokens = process_text(text, stopwords)\n",
    "        if tokens:  # 排除空列表\n",
    "            tokenized_docs.append(tokens)\n",
    "    return tokenized_docs\n",
    "\n",
    "weibo_tokenized = tokenize_comments(weibo_df, STOPS)"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "weibo_dictionary = corpora.Dictionary(weibo_tokenized)\n",
    "weibo_corpus = [weibo_dictionary.doc2bow(text) for text in weibo_tokenized]\n",
    "\n",
    "# 查看词袋表示\n",
    "print(weibo_corpus)"
   ],
   "id": "e3b020324fbe5958"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# 设置主题数，例如 5 个主题\n",
    "num_topics = 5\n",
    "\n",
    "# 训练 LDA 模型\n",
    "lda = LdaModel(weibo_corpus, num_topics=num_topics, id2word=weibo_dictionary, passes=15)\n",
    "\n",
    "# 查看每个主题的 Top 10 词\n",
    "topics = lda.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ],
   "id": "2e7c576b7492a26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# 可视化 LDA 模型\n",
    "vis = pyLDAvis.gensim.prepare(lda, weibo_corpus, weibo_dictionary)\n",
    "\n",
    "# 保存成 HTML 文件\n",
    "pyLDAvis.save_html(vis, '{output_path}/weibo_lda_visualization.html')"
   ],
   "id": "609e74f3be9d8d23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "def evaluate_lda_coherence(texts, dictionary, start=3, end=15, step=1, passes=10, plot=True):\n",
    "    \"\"\"\n",
    "    尝试不同的 num_topics，计算 Coherence 得分，帮助选择最佳主题数。\n",
    "    \n",
    "    参数:\n",
    "        texts: 分词后的文本列表（List[List[str]]）\n",
    "        dictionary: gensim 生成的 Dictionary 对象\n",
    "        start: 最小主题数（默认 3）\n",
    "        end: 最大主题数（默认 15）\n",
    "        step: 步长（默认 1）\n",
    "        passes: LDA 模型训练的 passes 参数\n",
    "        plot: 是否绘图（默认 True）\n",
    "        \n",
    "    返回:\n",
    "        models: 所有 LDA 模型的列表\n",
    "        coherence_scores: 对应的一致性得分列表\n",
    "    \"\"\"\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "    topic_range = range(start, end + 1, step)\n",
    "\n",
    "    print(\"正在尝试不同的主题数...\")\n",
    "    for num_topics in tqdm(topic_range):\n",
    "        lda_model = LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=num_topics,\n",
    "            passes=passes,\n",
    "            random_state=42\n",
    "        )\n",
    "        coherence_model = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        score = coherence_model.get_coherence()\n",
    "        models.append(lda_model)\n",
    "        coherence_scores.append(score)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(topic_range, coherence_scores, marker='o')\n",
    "        plt.title('主题数 vs 一致性得分 (Coherence)')\n",
    "        plt.xlabel('主题数 (num_topics)')\n",
    "        plt.ylabel('Coherence Score (c_v)')\n",
    "        plt.xticks(topic_range)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.show()\n",
    "\n",
    "    return models, coherence_scores"
   ],
   "id": "810ffa7db2c6f73a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "weibo_models, weibo_scores = evaluate_lda_coherence(\n",
    "    texts=weibo_tokenized,           # 你的分词数据\n",
    "    dictionary=weibo_dictionary,           # gensim Dictionary\n",
    "    start=3,\n",
    "    end=12,\n",
    "    step=1,\n",
    "    passes=10\n",
    ")"
   ],
   "id": "2ba05aa99c616426"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for i in range(len(weibo_models)):\n",
    "    # 可视化 LDA 模型\n",
    "    vis = pyLDAvis.gensim.prepare(weibo_models[i], weibo_corpus, weibo_dictionary)\n",
    "    \n",
    "    # 保存成 HTML 文件\n",
    "    pyLDAvis.save_html(vis, f'{output_path}/weibo_lda_visualization_{i}.html')"
   ],
   "id": "42e15205f683779c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
